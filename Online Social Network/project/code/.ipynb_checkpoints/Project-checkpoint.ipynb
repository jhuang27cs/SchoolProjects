{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "# don't run it , the path already exist after we build this\n",
    "os.makedirs('data/pos')\n",
    "os.makedirs('data/neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import io\n",
    "def write_to_file(typ, name, path, content):\n",
    "    completeName = os.path.join(path, typ+name +\".txt\")\n",
    "#     content = content.encode('ascii', 'ignore').decode('ascii')\n",
    "    file1 = io.open(completeName, \"w\", encoding='utf8')\n",
    "    file1.write(content)\n",
    "    file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 1000 positive reviews\n",
      "read 1000 negative reviews\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "# retrieve the positive reviews and negative 1000reviews from the Yelp dataset\n",
    "# to build the training set\n",
    "i = 0\n",
    "j = 0\n",
    "with open(\"yelp_academic_dataset.json\", 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        business_json = json.loads(line)\n",
    "        if \"review_id\" in business_json:\n",
    "            if business_json[\"stars\"] > 3.5 and i < 1000:\n",
    "                write_to_file('pos', str(i), 'data/pos', business_json[\"text\"])\n",
    "                i += 1\n",
    "            elif business_json[\"stars\"] < 2.5 and j < 1000:\n",
    "                write_to_file('neg', str(j), 'data/neg', business_json[\"text\"])\n",
    "                j += 1\n",
    "        if i == 1000 and j == 1000:\n",
    "            break\n",
    "print(\"read %i positive reviews\\nread %i negative reviews\" % (i, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subdirectories are:['neg', 'pos']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Here is the path to the data directory.\n",
    "path = 'data'\n",
    "print('subdirectories are:' + str(os.listdir(path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_files(path):\n",
    "    \"\"\" Return a list of file names in this directory that end in .txt \n",
    "    The list should be sorted alphabetically by file name.\n",
    "    Params:\n",
    "        path....a directory containing .txt review files.\n",
    "    Returns:\n",
    "        a list of .txt file names, sorted alphabetically.\n",
    "    \"\"\"\n",
    "    return sorted([path + os.sep + file for file in os.listdir(path) if file.endswith(\".txt\")]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 1000 positive and 1000 negative training files\n",
      "first positive file: data/pos/pos0.txt\n",
      "first negative file: data/neg/neg0.txt\n"
     ]
    }
   ],
   "source": [
    "pos_train_files = get_files(path + os.sep + 'pos')\n",
    "neg_train_files = get_files(path + os.sep + 'neg')\n",
    "all_train_files = pos_train_files + neg_train_files\n",
    "\n",
    "print('found %d positive and %d negative training files' %\n",
    "      (len(pos_train_files), len(neg_train_files)))\n",
    "print('first positive file: %s' % pos_train_files[0])\n",
    "print('first negative file: %s' % neg_train_files[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 3 and last 3 labels are: [1 1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "def get_true_labels(file_names):\n",
    "    \"\"\"Return a *numpy array* of ints for the true sentiment labels of each file.\n",
    "    1 means positive, 0 means negative. Use the name of the file to determine\n",
    "    the true label.\n",
    "    Params:\n",
    "        file_names....a list of .txt file paths, e.g., data/train/pos/10057_9.txt\n",
    "    Returns:\n",
    "        a numpy array of 1 or 0 values corresponding to each element\n",
    "        of file_names, where 1 indicates a positive review, and 0\n",
    "        indicates a negative review.\n",
    "    \"\"\"\n",
    "    def get_label(file):\n",
    "        if 'pos' in re.sub('\\W+',' ', file).split():\n",
    "            return 1\n",
    "        elif 'neg' in re.sub('\\W+',' ', file).split():\n",
    "            return 0\n",
    "    return np.array([get_label(file) for file in file_names])\n",
    "labels = get_true_labels(all_train_files)\n",
    "print('first 3 and last 3 labels are: %s' % str(labels[[1,2,3,-3,-2,-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"We had a small dog with us so we were limited to places that had outdoor dining while at Stanford Shopping Center.  Babbo's caught our eye and we took a seat.  We had no particular expectations but all three of us were extremely pleased with our meals, mine was the Gorgonzola and pine nut pizza which was amazing.  Babbo himself even stopped by our table to chat indicating that his restaurant had been in business there for over 20 years. We'll definitely be back.\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "def file2string(filename):\n",
    "    return io.open(filename, encoding='utf8').readlines()[0]\n",
    "file2string(pos_train_files[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'movie',\n",
       " 'is',\n",
       " 'not',\n",
       " 'not_good',\n",
       " 'not_.',\n",
       " 'in',\n",
       " 'fact',\n",
       " ',',\n",
       " 'it',\n",
       " 'is',\n",
       " 'not',\n",
       " 'not_even',\n",
       " 'not_really',\n",
       " 'a',\n",
       " 'movie',\n",
       " '.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def tokenize_with_not(text):\n",
    "    \"\"\"\"Given a string, return a list of tokens such that: (1) all\n",
    "    tokens are lowercase, (2) all punctuation is kept as separate tokens.\n",
    "    Note that underscore (_) is not considered punctuation. (3)whenever the term 'not' appears, \n",
    "    change the two subsequent tokens to have the prefix 'not_' prior to the token. \n",
    "    See the example below. \n",
    "    Params:\n",
    "        text....a string\n",
    "    Returns:\n",
    "        a list of tokens\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return []\n",
    "    text = text.lower()\n",
    "    tokens = []\n",
    "    tokens = re.findall(r\"[\\w]+|[^\\w\\s\\x85]\", text)\n",
    "    indices = [i for i, x in enumerate(tokens) if x == \"not\"]\n",
    "    j = []\n",
    "    i = 0\n",
    "    for token in tokens:\n",
    "        if i in indices:\n",
    "            j.append(i + 1)\n",
    "            j.append(i + 2)\n",
    "        if i in j:\n",
    "            tokens[i]=('not_'+token)\n",
    "        i += 1 \n",
    "    return tokens\n",
    "\n",
    "tokenize_with_not(\"This movie is not good. In fact, it is not even really a movie.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix represents 2000 documents with 15505 features\n",
      "first doc has terms:\n",
      "[0, 6, 11, 13, 307, 671, 693, 745, 932, 1482, 1921, 2058, 2731, 2835, 2993, 3225, 3308, 3429, 3581, 3666, 3682, 4217, 4726, 4826, 4928, 5181, 5301, 5398, 5616, 5989, 6122, 6142, 6521, 6526, 6631, 6777, 6947, 7292, 7305, 7544, 7672, 7774, 7896, 8462, 9745, 9814, 10143, 10351, 10513, 10677, 11666, 11869, 12241, 12796, 12840, 13440, 13441, 13697, 13700, 13866, 13871, 13905, 13922, 13934, 14058, 14111, 14269, 14314, 14726, 14785, 15132, 15231]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\"\"\"As we already tested in the homework, tokenize_with_not results in slightly higher accuracy. \n",
    "So, we use that to do the vectorize.\n",
    "\"\"\"\n",
    "def do_vectorize(filenames, tokenizer_fn=tokenize_with_not, min_df=1,\n",
    "                 max_df=1., binary=True, ngram_range=(1,1)):\n",
    "    \"\"\"\n",
    "    Convert file into a sparse csr_matrix, where\n",
    "    each row is a file and each column represents a unique word.\n",
    "    Use sklearn's CountVectorizer: http://goo.gl/eJ2PJ5\n",
    "    Params:\n",
    "        filenames.......list of review file names\n",
    "        tokenizer_fn....the function used to tokenize each document\n",
    "        min_df..........remove terms from the vocabulary that don't appear\n",
    "                        in at least this many documents\n",
    "        max_df..........remove terms from the vocabulary that appear in more\n",
    "                        than this fraction of documents\n",
    "        binary..........If true, each documents is represented by a binary\n",
    "                        vector, where 1 means a term occurs at least once in \n",
    "                        the document. If false, the term frequency is used instead.\n",
    "        ngram_range.....A tuple (n,m) means to use phrases of length n to m inclusive.\n",
    "                        E.g., (1,2) means consider unigrams and bigrams.\n",
    "    Return:\n",
    "        A tuple (X, vec), where X is the csr_matrix of feature vectors,\n",
    "        and vec is the CountVectorizer object.\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    ###\n",
    "    vec = CountVectorizer(input ='filename',tokenizer=tokenizer_fn, ngram_range=ngram_range,  max_df=max_df, min_df=min_df,binary = binary)\n",
    "    X = vec.fit_transform(filename for filename in filenames)\n",
    "    return (X,vec)\n",
    "matrix, vec = do_vectorize(all_train_files)\n",
    "print ('matrix represents %d documents with %d features' % (matrix.shape[0], matrix.shape[1]))\n",
    "print('first doc has terms:\\n%s' % (str(sorted(matrix[0].nonzero()[1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first shuffled document data/pos/pos204.txt has label 1 and terms: [0, 6, 7, 8, 11, 13, 745, 998, 1398, 2247, 2484, 2499, 2861, 3239, 3877, 4322, 4693, 4733, 4936, 4982, 5282, 5426, 5761, 6017, 6521, 6631, 6687, 6947, 6961, 7129, 7656, 8252, 8520, 9812, 9875, 9919, 10398, 10508, 10599, 11095, 11356, 11898, 12243, 12247, 12769, 13682, 13871, 13930, 14015, 14022, 14058, 14726, 15124]\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "# DThis is to randomize the order of the documents, but\n",
    "# in a way that is consistent across platforms.\n",
    "# See: http://stackoverflow.com/a/18992474/1756896\n",
    "def repeatable_random(seed):\n",
    "    hash = str(seed)\n",
    "    while True:\n",
    "        hash = hashlib.md5(hash).digest()\n",
    "        for c in hash:\n",
    "            yield ord(c)\n",
    "\n",
    "def repeatable_shuffle(X, y, filenames):\n",
    "    r = repeatable_random(42) \n",
    "    indices = sorted(range(X.shape[0]), key=lambda x: next(r))\n",
    "    return X[indices], y[indices], np.array(filenames)[indices]\n",
    "\n",
    "X, y, filenames = repeatable_shuffle(matrix, labels, all_train_files)\n",
    "\n",
    "print('first shuffled document %s has label %d and terms: %s' % \n",
    "      (filenames[0], y[0], sorted(X[0].nonzero()[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Create a LogsticRegression object\n",
    "def get_clf():\n",
    "    return LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 accuracy=0.85\n",
      "fold 1 accuracy=0.82\n",
      "fold 2 accuracy=0.8425\n",
      "fold 3 accuracy=0.815\n",
      "fold 4 accuracy=0.84\n",
      "average cross validation accuracy=0.8335\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "def do_cross_validation(X, y, n_folds=5, verbose=False):\n",
    "    \"\"\"\n",
    "    Perform n-fold cross validation, calling get_clf() to train n\n",
    "    different classifiers. Use sklearn's KFold class: http://goo.gl/wmyFhi\n",
    "    Be sure not to shuffle the data, otherwise your output will differ.\n",
    "    Params:\n",
    "        X.........a csr_matrix of feature vectors\n",
    "        y.........the true labels of each document\n",
    "        n_folds...the number of folds of cross-validation to do\n",
    "        verbose...If true, report the testing accuracy for each fold.\n",
    "    Return:\n",
    "        the average testing accuracy across all folds.\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    ###\n",
    "    cv = KFold(len(y), n_folds = n_folds)\n",
    "    accuracies = []\n",
    "    for train_idx, test_idx in cv:\n",
    "        clf = get_clf()\n",
    "        clf.fit(X[train_idx], y[train_idx])\n",
    "        predicted = clf.predict(X[test_idx])\n",
    "        acc = accuracy_score(y[test_idx], predicted)\n",
    "        accuracies.append(acc)\n",
    "    if (verbose == True):\n",
    "        for i in range(n_folds):\n",
    "            print('fold %d accuracy=%s' % (i, accuracies[i]))\n",
    "    avg = np.mean(accuracies)\n",
    "    return avg\n",
    "print('average cross validation accuracy=%.4f' %\n",
    "      do_cross_validation(X, y, verbose=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def do_expt(filenames, y, tokenizer_fn=tokenize_with_not,\n",
    "            min_df=1, max_df=1., binary=True,\n",
    "            ngram_range=(1,1), n_folds=5):\n",
    "    \"\"\"\n",
    "    Run one experiment, which consists of vectorizing each file,\n",
    "    performing cross-validation, and returning the average accuracy.\n",
    "    Params:\n",
    "        filenames.......list of review file names\n",
    "        y...............the true sentiment labels for each file\n",
    "        tokenizer_fn....the function used to tokenize each document\n",
    "        min_df..........remove terms from the vocabulary that don't appear\n",
    "                        in at least this many documents\n",
    "        max_df..........remove terms from the vocabulary that appear in more\n",
    "                        than this fraction of documents\n",
    "        binary..........If true, each documents is represented by a binary\n",
    "                        vector, where 1 means a term occurs at least once in \n",
    "                        the document. If false, the term frequency is used instead.\n",
    "        ngram_range.....A tuple (n,m) means to use phrases of length n to m inclusive.\n",
    "                        E.g., (1,2) means consider unigrams and bigrams.\n",
    "        n_folds.........The number of cross-validation folds to use.\n",
    "    Returns:\n",
    "        the average cross validation testing accuracy.\n",
    "    \"\"\"\n",
    "    matr, vec = do_vectorize(filenames, tokenizer_fn=tokenizer_fn, min_df=min_df,\n",
    "                 max_df=max_df, binary=binary, ngram_range=ngram_range)\n",
    "    return do_cross_validation(matr, y, n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy using default settings: 0.8335\n"
     ]
    }
   ],
   "source": [
    "print('accuracy using default settings: %.4g' % do_expt(filenames, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEQCAYAAABxzUkqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109c77310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.82399999999999995,\n",
       " 0.83350000000000013,\n",
       " 0.84250000000000003,\n",
       " 0.84049999999999991]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\"\"\"Try out a few different settings to see how they affect cross-validation accuracy.\"\"\"\n",
    "def compare_n_folds(filenames, y):\n",
    "    \"\"\"\n",
    "    Vary the setting of n_folds parameter in the do_expt \n",
    "    function to be in [2,5,10,20]. For each setting, call do_expt and \n",
    "    store the resulting accuracy. Plot the accuracies for each setting.\n",
    "    Also return the list of accuracies. Use the default value for all\n",
    "    other arguments to the do_expt function.\n",
    "    Params:\n",
    "        filenames....list of training file names\n",
    "        y............true labels for each file (a numpy array)\n",
    "    Returns:\n",
    "        a list of average testing accuracies, one per fold.\n",
    "    \"\"\"\n",
    "    L = [2, 5, 10, 20]\n",
    "    accuracies = []\n",
    "    for i in L:\n",
    "        acc = do_expt(filenames, y, n_folds = i)\n",
    "        accuracies.append(acc)\n",
    "    plt.figure()\n",
    "    plt.plot(L, accuracies, 'bo-')\n",
    "    plt.xlabel('n_folds')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.show()\n",
    "    return accuracies\n",
    "compare_n_folds(filenames, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the accuracy increases as the number of folds increases before 10 and decreases after that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.83350000000000013, 0.82400000000000007]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_binary(filenames, y):\n",
    "    \"\"\"\n",
    "    Call do_expt twice, once with binary=True, and once with binary=False.\n",
    "    Return the average accuracies for each. Use the default parameters for the\n",
    "    remaining arguments in do_expt.\n",
    "    Params:\n",
    "        filenames....list of training file names\n",
    "        y............true labels for each file (a numpy array)\n",
    "    Returns:\n",
    "        a list of average testing accuracies. The first entry\n",
    "        is for binary=True, the second is for binary=False.\n",
    "    \"\"\"\n",
    "    accuracies = []\n",
    "    accuracies.append(do_expt(filenames, y, binary = True))\n",
    "    accuracies.append(do_expt(filenames, y, binary = False))\n",
    "    return accuracies\n",
    "compare_binary(filenames, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the accuracy of binary has higher accuracy. And binary feature vectors does better than using term frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEQCAYAAABxzUkqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1058358d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.83350000000000013,\n",
       " 0.83350000000000013,\n",
       " 0.83350000000000013,\n",
       " 0.83499999999999996,\n",
       " 0.83149999999999991,\n",
       " 0.83299999999999996,\n",
       " 0.83350000000000013,\n",
       " 0.83200000000000007,\n",
       " 0.82900000000000007,\n",
       " 0.83149999999999991]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def min_df_expt(filenames, y):\n",
    "    \"\"\"\n",
    "    Vary the setting of min_df parameter in the do_expt \n",
    "    function to be ints in the range (1,10) (inclusive). For each setting,\n",
    "    call do_expt and store the resulting accuracy. Plot the accuracies for each setting.\n",
    "    Also return the list of accuracies. Use the default value for all\n",
    "    other arguments to the do_expt function.\n",
    "    Params:\n",
    "        filenames....list of training file names\n",
    "        y............true labels for each file (a numpy array)\n",
    "    Returns:\n",
    "        a list of average testing accuracies, one per min_df value.\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    ###\n",
    "    accuracies = []\n",
    "    for i in range(1,11):\n",
    "        accuracies.append(do_expt(filenames, y, min_df=i, tokenizer_fn=tokenize_with_not))\n",
    "    plt.figure()\n",
    "    plt.plot(range(1,11), accuracies, 'bo-')\n",
    "    plt.xlabel('min_df')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.show()\n",
    "    return accuracies\n",
    "min_df_expt(filenames, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The best accuracy occurs when min_df=4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEQCAYAAACa+vIpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109764b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.81849999999999989,\n",
       " 0.81899999999999995,\n",
       " 0.82599999999999996,\n",
       " 0.82750000000000001,\n",
       " 0.83700000000000008,\n",
       " 0.83399999999999996,\n",
       " 0.83050000000000002,\n",
       " 0.83499999999999996,\n",
       " 0.83350000000000013,\n",
       " 0.83499999999999996]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def max_df_expt(filenames, y):\n",
    "    \"\"\"\n",
    "    Vary the setting of max_df parameter in the do_expt \n",
    "    function to be one of [.1, .2, .3, .4, .5, .6, .7, .8, .9, 1.].\n",
    "    For each setting, call do_expt and store the resulting accuracy.\n",
    "    Plot the accuracies for each setting. Also return the list of accuracies.\n",
    "    Use the default value for all other arguments to the do_expt function,\n",
    "    except that the min_df=4.\n",
    "    Params:\n",
    "        filenames....list of training file names\n",
    "        y............true labels for each file (a numpy array)\n",
    "    Returns:\n",
    "        a list of average testing accuracies, one per max_df value.\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    ###\n",
    "    L = [.1, .2, .3, .4, .5, .6, .7, .8, .9, 1.]\n",
    "    accuracies = []\n",
    "    for i in L:\n",
    "        accuracies.append(do_expt(filenames, y, min_df=4, max_df=i, tokenizer_fn=tokenize_with_not))\n",
    "    plt.figure()\n",
    "    plt.plot(L, accuracies, 'bo-')\n",
    "    plt.xlabel('max_df')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.show()\n",
    "    return accuracies\n",
    "max_df_expt(filenames, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# So, based on the above experiments, we set:\n",
    "# binary=True\n",
    "# min_df=4\n",
    "# max_df=.5\n",
    "# This results in 5-fold cross-validation accuracy of 83.7%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Next we'll look at the coefficients learned by LogisticRegression \n",
    "# to determine how it is making its classification decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
       "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, we'll train our final classifier using our best settings.\n",
    "X, vec = do_vectorize(filenames, tokenizer_fn=tokenize_with_not,\n",
    "                      binary=True, min_df=4, max_df=.5)\n",
    "clf = get_clf()\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The LogisticRegression variable (clf) has an attribute .coef_, \n",
    "# which are the learned model coefficients. \n",
    "# This is a numpy array with a real value for each term in the vocabulary. \n",
    "# Positive values indicate a correlation with the positive class, \n",
    "# negative values indicate a correlation with the negative class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "(1, 4305)\n"
     ]
    }
   ],
   "source": [
    "print type(clf.coef_)\n",
    "print clf.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99050439 -0.616187    0.20980402  0.09418665  0.13396639  0.21229277\n",
      " -0.11513765  0.49518438  0.08935452  0.44053089]\n",
      "[u'!', u'\"', u'#', u'$', u'%', u'&', u'(', u')', u'*', u'+']\n"
     ]
    }
   ],
   "source": [
    "# Here are the first 10 coefficients.\n",
    "print(clf.coef_[0][:10])\n",
    "# The features corresponding to them can be found using the vectorizer's get_feature_names method.\n",
    "print(vec.get_feature_names()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top positive coefs: [(u'great', 1.4107145140809538), (u'delicious', 1.3132225228827401), (u'amazing', 1.2191324889159598), (u'excellent', 1.1955727549662649), (u'best', 1.1290703461982552), (u'clean', 1.0901066699611568), (u'perfect', 1.0669638361318279), (u'awesome', 1.063565124567138), (u'worth', 1.0527392759850707), (u'good', 1.0512215948987491)]\n",
      "top negative coefs: [(u'worst', -1.5229425197573578), (u'dry', -1.3469728589615695), (u'mediocre', -1.2603609003812708), (u'terrible', -1.2453145981956382), (u'greasy', -1.1875412243352557), (u'overpriced', -1.1333359784292718), (u'disappointed', -1.0866906489707888), (u'ok', -0.99756189658134542), (u'awful', -0.99030672731654568), (u'not', -0.98224641650995304)]\n"
     ]
    }
   ],
   "source": [
    "def get_top_coefficients(clf, vec, n=10):\n",
    "    \"\"\" Get the top n coefficients for each class (positive/negative).\n",
    "    Params:\n",
    "        clf...a LogisticRegression object that has already been fit to data.\n",
    "        vec...a CountVectorizer\n",
    "        n.....the number of features to print per class.\n",
    "    Returns:\n",
    "        Two lists of tuples. The first list containts the top terms for the positive\n",
    "        class. Each entry is a tuple of (string, float) pairs, where\n",
    "        string is the feature name and float is the coefficient.\n",
    "        The second list is the same but for the negative class.\n",
    "        In each list, entries should be sorted in descending order of \n",
    "        absolute value.\"\"\"\n",
    "    pos_coef = []\n",
    "    neg_coef = []\n",
    "    coef = clf.coef_[0]\n",
    "    sort = np.argsort(coef)\n",
    "    posi = sort[::-1][:n]\n",
    "    negi = sort[:n]\n",
    "    terms = vec.get_feature_names()\n",
    "    for i in posi:\n",
    "        pos_coef.append((terms[i], coef[i]))\n",
    "    for i in negi:\n",
    "        neg_coef.append((terms[i], coef[i]))\n",
    "    return pos_coef, neg_coef\n",
    "        \n",
    "pos_coef, neg_coef = get_top_coefficients(clf, vec, n=10)\n",
    "print('top positive coefs: %s' % str(pos_coef))\n",
    "print('top negative coefs: %s' % str(neg_coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build test data files \n",
    "import os.path\n",
    "# don't run it , the path already exist after we build this\n",
    "os.makedirs('test/pos')\n",
    "os.makedirs('test/neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 1000 positive reviews\n",
      "read 1000 negative reviews\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# retrieve the next positive reviews and negative 1000reviews from the Yelp dataset\n",
    "# to build the training set\n",
    "i = 0\n",
    "j = 0\n",
    "numi = 0\n",
    "numj = 0\n",
    "with open(\"yelp_academic_dataset.json\", 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        business_json = json.loads(line)\n",
    "        if \"review_id\" in business_json:\n",
    "            if business_json[\"stars\"] > 3.5 and i < 2000:\n",
    "                if i >= 1000:\n",
    "                    write_to_file('pos', str(i), 'test/pos', business_json[\"text\"])\n",
    "                    numi += 1\n",
    "                i += 1\n",
    "            elif business_json[\"stars\"] < 2.5 and j < 2000:\n",
    "                if j >= 1000:\n",
    "                    write_to_file('neg', str(j), 'test/neg', business_json[\"text\"])\n",
    "                    numj += 1\n",
    "                j += 1\n",
    "        if i == 2000 and j == 2000:\n",
    "            break\n",
    "print(\"read %i positive reviews\\nread %i negative reviews\" % (numi, numj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test represents 2000 documents with 4305 features\n",
      "y_test has 1000 positive and 1000 negative labels\n",
      "first testing file is test/pos/pos1000.txt\n",
      "last testing file is test/neg/neg1999.txt\n",
      "testing accuracy=0.859\n"
     ]
    }
   ],
   "source": [
    "# Do not modify.\n",
    "test_path = 'test'\n",
    "pos_test_files = get_files(test_path + os.sep + 'pos')\n",
    "neg_test_files = get_files(test_path + os.sep + 'neg')\n",
    "all_test_files = pos_test_files + neg_test_files\n",
    "# Note that we call .transform, not .fit_transform, since we \n",
    "# don't want to learn a new vocabulary.\n",
    "X_test = vec.transform(all_test_files)\n",
    "y_test = np.array([1] * len(pos_test_files) + [0] * len(neg_test_files))\n",
    "print('X_test represents %d documents with %d features' % (X_test.shape[0], X_test.shape[1]))\n",
    "print('y_test has %d positive and %d negative labels' % (len(np.where(y_test==1)[0]),\n",
    "                                                          len(np.where(y_test==0)[0])))\n",
    "print('first testing file is %s' % all_test_files[0])\n",
    "print('last testing file is %s' % all_test_files[-1])\n",
    "print('testing accuracy=%.4g' % accuracy_score(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# So, our testing accuracy is 85.9%, which is pretty close to our estimated accuracy of 83.7%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import ConfigParser\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import sys\n",
    "import time\n",
    "from TwitterAPI import TwitterAPI\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def get_twitter(config_file):\n",
    "    \"\"\" Read the config_file and construct an instance of TwitterAPI.\n",
    "    Args:\n",
    "      config_file ... A config file in ConfigParser format with Twitter credentials\n",
    "    Returns:\n",
    "      An instance of TwitterAPI.\n",
    "    \"\"\"\n",
    "    config = ConfigParser.ConfigParser()\n",
    "    config.read(config_file)\n",
    "    twitter = TwitterAPI(\n",
    "                   config.get('twitter', 'consumer_key'),\n",
    "                   config.get('twitter', 'consumer_secret'),\n",
    "                   config.get('twitter', 'access_token'),\n",
    "                   config.get('twitter', 'access_token_secret'))\n",
    "    return twitter\n",
    "\n",
    "twitter = get_twitter('twitter.cfg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def robust_request(twitter, resource, params, max_tries=5):\n",
    "    \"\"\" If a Twitter request fails, sleep for 15 minutes.\n",
    "    Do this at most max_tries times before quitting.\n",
    "    Args:\n",
    "      twitter .... A TwitterAPI object.\n",
    "      resource ... A resource string to request.\n",
    "      params ..... A parameter dictionary for the request.\n",
    "      max_tries .. The maximum number of tries to attempt.\n",
    "    Returns:\n",
    "      A TwitterResponse object, or None if failed.\n",
    "    \"\"\"\n",
    "    for i in range(max_tries):\n",
    "        request = twitter.request(resource, params)\n",
    "        if request.status_code == 200:\n",
    "            return request\n",
    "        else:\n",
    "            print >> sys.stderr, 'Got error:', request.text, '\\nsleeping for 15 minutes.'\n",
    "            sys.stderr.flush()\n",
    "            time.sleep(61 * 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_friends(screen_name):\n",
    "    \"\"\" Return a list of the users that this person follows on Twitter, up to 200.\n",
    "    See https://dev.twitter.com/rest/reference/get/friends/list \n",
    "    Note, because of rate limits, it's best to test this method for one candidate before trying\n",
    "    on all candidates.\n",
    "    \n",
    "    Args:\n",
    "        screen_name: a string of a Twitter screen name\n",
    "    Returns:\n",
    "        A list of strings, one per friend.\n",
    "    Note: Many users follow more than 200 accounts; we will limit ourselves to\n",
    "    the first 200 accounts returned.\n",
    "    \"\"\"\n",
    "    request = twitter.request('friends/list', {'screen_name': screen_name, 'count':200})\n",
    "    r=[]\n",
    "    for a in request:\n",
    "        r.append(a['screen_name'])\n",
    "    return r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_all_friends(screen_names):\n",
    "    \"\"\" Get the friends for all the users in usernames.\n",
    "    Args:\n",
    "        screen_names: a list of Twitter screen names\n",
    "    Returns:\n",
    "        a dict mapping each candidate's username (string) to a list of his/her friends (strings)\n",
    "    \"\"\"\n",
    "    return {n: get_friends(n) for n in screen_names}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# don't run this just make dir for tweets\n",
    "import os.path\n",
    "restaurant=file2string('restaurant.txt')\n",
    "key=restaurant.split(' ')\n",
    "for item in key:\n",
    "    os.makedirs('data/tweets/%s'%item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_restaurant_tweet(key):\n",
    "    r = twitter.request('search/tweets', {'q':key,'count':10000})\n",
    "    tweets=[]\n",
    "    i=0\n",
    "    for item in r.get_iterator():\n",
    "        write_to_file('', item['user']['screen_name'], 'data/tweets/'+key, item[\"text\"])\n",
    "        i=i+1\n",
    "restaurant=file2string('restaurant.txt')\n",
    "key=restaurant.split(' ')\n",
    "for item in key:\n",
    "    get_restaurant_tweet(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score of restaurant PandaExpress = 42\n",
      "score of restaurant ChipotleTweets = 43\n",
      "score of restaurant Cheesecake = 86\n",
      "We recommand Cheesecake to our users\n",
      "__hnby has positive sentiment for Cheesecake,sentiment value:[1]\n",
      "__hnby likes Cheesecake!\n",
      "Hi krisyaasyeeken! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi naimalfaruk! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi OutfitsHeaven! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi FatyaEdDeen! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi LvxiB! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi F00DP0RN! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi FoodPornMenu! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi FoodPorn! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi RealFoodPorn_! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi TheeFoodPorn! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi FoodPornsx! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi ItsFoodPorn! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi DreamHouseX! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi naurah_lalaa! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi AzzazzillHu! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi ItsFoodsPorn! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi MhdAzhan! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi jamesxreid! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi Latiptop_! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi FifiNurfarisha! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi ooohhamin! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi IlhamSkrillex_! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi AtiqaRahim_! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi noreeqmal! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi MrdhyyhZhri! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi izzatyadnan_! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi nuridelin! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi _dianawahid! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi sportgirlbella! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi HeartBio! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi Kecillicious! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi _abdrhm! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi flwrdiy! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi warisn9! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi AyeenDenn! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi KimiRosli! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi KhairaKhrzzmn! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi ShoeiPorn! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi therealzulk! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi HlMQuotes! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi faktaanakkedua_! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi theshwlf! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi fateynfiefah! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi KissAppSL! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi apponeplus! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi hzwnhzq! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi tweetsemuaa! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi nurara_! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi artfulsadness! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi imdanielpadilla! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi bernardokath! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi bookmsgs! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi tylermckeever_! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi girlfeeIing! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi svldt! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi anxietyisyou! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi VansPorns! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi kv_life! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi BestTextMsgs! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi dailytxtmsg! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi AccurateText! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi diadelosquote_! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi NDHofficial! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi itssixwordstory! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi autocorrects! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi wordsporns! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi WisdomQuotees! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi QuotesDetail! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi LetsWearThat! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi LovePhrase! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi awakcomelsaya! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi SweetLoveMsg! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi _merecik! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi soulfuldares! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi instagram! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi VictoriasSecret! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi httpsepul! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi MujahidahSado! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi Syzryn! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi MegatAD! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi Sfiameyl_! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi YazidFazid! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi HazdiI! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi _arifofficial! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi Amiewa_husna! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi officiallfranzs! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi iSyafiqKyle! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi cklar_amal! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi AzimmAmiziee! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi FlyMasterBlue! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi qiszarry! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi MieyaRaudhah! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi IIntanSyahirahh! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi nashaannisa98! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi SFNorr_Khadijah! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi hasnidahussin! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi aqilah_n! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi arninazira25! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi NashrulIkram_! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi MSabriena! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi doditointoin! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi aidansyrn! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi apip_xx! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi Syami_Sam! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi MimiIzzatty_! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi PaizAngah! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi peyjalll! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi WanMuhammadAudi! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi EymalZolkafli! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi _AhmadKhalid_! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi AyimQayyim! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi WanWanwingg! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi QQulya! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi AmirSuhailii! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi NuraliaIzzati! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi nurul_shawany97! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi fatensamsul94! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi GadisssSepi! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi aten_iman235! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi AmirahMia7! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi nyssazahari! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi syuhadamomot98! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi IntanMeoww! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi AdilaAdzman! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi AnakCikguAnuar! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi itsmesumayyah_! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi muhdxfiq_! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi khusairiamin! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi 97_aizat! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi RadeonMbps! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi ihvsnx! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi HatiPerluSado! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi hvziqm! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi AmirAidit! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi ShahLorston! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi shabarrina! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi nakirnelly! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi luqmxndew! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi IskndrZlqrnain! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi mohdaqqilikram! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi faidhi_fahmy! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi khrnnis_! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi sitirauhah_! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi Farah_Nafisah_! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi Kazen_Sensai13! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi RohAdekFly! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi MiraUlala1! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi ermillaaa_! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi shahrielsanders! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi _eijaaa! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi RahsyaMarley! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi acai_hudsonIV! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi _suhailiayub! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi NazihahI! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi nurfitrahhalim! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi Darwisha_Ahmad! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi my_aniez! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi _aidaayb! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi _mighaaa! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi EhhFarhannn! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi nrlnjwa_! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi _nazmimoktar! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi FyrSukor_! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi Aniemm_! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi nurbahirah_k! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi Muhd_oggy! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi _junnur! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi EhhSengettttt! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi zatyfana98! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi AjwadAzibNoor! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi nurulfaika2! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi hazriqxaxau! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi nfadhli__! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi akimx_! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi aainazem! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi AfiEika! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi AmarAiman_! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi NaimRizuanx! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi Faiz_Annuar! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi EmyHeavens! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi akidzafri! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi AkuKauRasa! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi Ehayinn! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi JohnLaa_! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi Myrull95! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi EhhFrinky! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi Zikri_Rajaii! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi HanisQistina! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi ryzzuxnyunus! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi ShahrulSuhaimi_! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi IzzaIzzat! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi ZacAlikasturi! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi shah_syawal! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi ikhwannHanif! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi nasirruddin98! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi polkaCen! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi Zariffff_! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi taktauname! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi nurfatiha_husna! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n",
      "Hi abie_biey! Your friend __hnby likes Cheesecake, get yourself some delicious food.\n"
     ]
    }
   ],
   "source": [
    "#for those who dont have any friends tweet about any restaurant,we recommand a restaurant based on sentiment collected\n",
    "#from twitter\n",
    "def recommandation(screen_name,key):\n",
    "    names=get_friends(screen_name)\n",
    "#     print names\n",
    "    for name in names:\n",
    "        print('Hi %s! Your friend %s likes %s, get yourself some delicious food.'%(name,screen_name,key))\n",
    "\n",
    "def restaurant_socre(key):\n",
    "    file=get_files('data/tweets/'+key)\n",
    "    X_test = vec.transform(file)\n",
    "    r=clf.predict(X_test)\n",
    "    #print(r)\n",
    "    print('score of restaurant %s = %i' % (key,r.sum()))\n",
    "    return r\n",
    "restaurant=file2string('restaurant.txt')\n",
    "# print(restaurant)\n",
    "key=restaurant.split(' ')\n",
    "# print(key)\n",
    "score=[]\n",
    "j=0\n",
    "f=0\n",
    "for item in key:\n",
    "    score.append(restaurant_socre(item).sum())\n",
    "for i in range(0,len(key)):\n",
    "    if (score[i]>=f):\n",
    "        j=i\n",
    "        f=score[i]\n",
    "print ('We recommand %s to our users'%key[j])\n",
    "Flag=\".txt\"\n",
    "p='data/tweets/%s/'%key[j]\n",
    "# print (p)\n",
    "# print len(p)\n",
    "FileNames=os.listdir(p)\n",
    "for fn in FileNames:\n",
    "    if (Flag in fn):\n",
    "        fullfilename=os.path.join(p,fn)\n",
    "        X = vec.transform([fullfilename])\n",
    "        r=clf.predict(X)\n",
    "        if (r>0):\n",
    "            screen_name=fullfilename[len(p):len(fullfilename)-4]\n",
    "            print('%s has positive sentiment for %s,sentiment value:%s'%(screen_name,key[j],r))\n",
    "            print('%s likes %s!'%(screen_name,key[j]))\n",
    "            recommandation(screen_name,key[j])\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
